{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/annabramslow/Documents/Company2Vec\n"
     ]
    }
   ],
   "source": [
    "cd /Users/annabramslow/Documents/Company2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass, field\n",
    "from pathlib import Path\n",
    "from typing import List\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import pandas as pd\n",
    "\n",
    "#from ..decorators import save_parquet\n",
    "#from ..ops import sort_partitions\n",
    "#from ..serialize import DATA_ROOT\n",
    "#from .base import FIELD_TYPE, TokenSource\n",
    "#from src.decorators import save_parquet\n",
    "#from src.ops import sort_partitions\n",
    "#from base import FIELD_TYPE, TokenSource\n",
    "#from data_processing.helpers import enrich_with_asof_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dd_enrich_with_asof_values(\n",
    "    df: dd.DataFrame, \n",
    "    df_registrations: dd.DataFrame, \n",
    "    values=['Industry', 'CompanyType', 'Address', 'Status'], \n",
    "    date_col_df='FromDate', \n",
    "    date_col_registrations='FromDate'\n",
    ") -> dd.DataFrame:\n",
    "    \"\"\"\n",
    "    Adds the as-of values of df_registrations for the entries in df.\n",
    "    Allows different date column names for both dataframes.\n",
    "    \"\"\"\n",
    "\n",
    "    for value in values:\n",
    "        # Load data by filtering df_registrations on ChangeType\n",
    "        df_value = df_registrations.loc[df_registrations['ChangeType'] == value].reset_index(drop=True)\n",
    "\n",
    "        # Special handling for 'Status' value: replace NaN dates with '2000-01-01'\n",
    "        if value == 'Status':\n",
    "            df_value[date_col_registrations] = df_value[date_col_registrations].fillna('2000-01-01')\n",
    "\n",
    "        # Convert date columns to datetime if they are not already in datetime format\n",
    "        df[date_col_df] = dd.to_datetime(df[date_col_df], errors='coerce')\n",
    "        df_value[date_col_registrations] = dd.to_datetime(df_value[date_col_registrations], errors='coerce')\n",
    "\n",
    "        # Select relevant columns and rename 'NewValue' to the current value\n",
    "        df_value = df_value[['CVR', date_col_registrations, 'NewValue']].rename(columns={\n",
    "            date_col_registrations: date_col_df,  # Align the date column names\n",
    "            'NewValue': value  # Rename 'NewValue' to the specific value being processed\n",
    "        })\n",
    "\n",
    "        # Perform the asof merge using Dask's merge_asof function\n",
    "        df = dd.merge_asof(\n",
    "            df.sort_values(date_col_df),\n",
    "            df_value.sort_values(date_col_df),\n",
    "            on=date_col_df,\n",
    "            by='CVR',\n",
    "            direction='backward'\n",
    "        )\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_currency( df: dd.DataFrame, lookup_table: dd.DataFrame, \n",
    "                     amount_cols=['amount'],  # List of columns to convert\n",
    "                     currency_col='currency', \n",
    "                     date_col='PublicationDate',  # The datetime column in df\n",
    "                     ) -> dd.DataFrame:\n",
    "    \"\"\"\n",
    "    Convert multiple currency columns in the DataFrame based on a lookup table for rows where currency is not 'DKK'.\n",
    "    \n",
    "    Args:\n",
    "        df (dd.DataFrame): The main dataframe with amounts to convert.\n",
    "        lookup_table (dd.DataFrame): The lookup table containing conversion rates.\n",
    "        amount_cols (list): List of column names in df containing amounts to be converted.\n",
    "        currency_col (str): Column name in df containing currency information.\n",
    "        date_col (str): Column name for datetime in df to extract year and month from.\n",
    "    \n",
    "    Returns:\n",
    "        dd.DataFrame: DataFrame with currency conversion applied to the specified amount columns.\n",
    "    \"\"\"\n",
    "\n",
    "    # 1. Filter rows where the currency is not 'DKK'\n",
    "    non_dkk_df = df[df[currency_col] != 'DKK']\n",
    "    dkk_df = df[df[currency_col] == 'DKK']  # Keep these rows unchanged\n",
    "\n",
    "    # 2. Extract year and month from the PublicationDate column\n",
    "    non_dkk_df['year'] = non_dkk_df[date_col].dt.year\n",
    "    non_dkk_df['month'] = non_dkk_df[date_col].dt.month\n",
    "\n",
    "    # 3. Perform a join to find the correct rate for each non-DKK row\n",
    "    merged_df = dd.merge(\n",
    "        non_dkk_df,\n",
    "        lookup_table,\n",
    "        left_on=[currency_col, 'year', 'month'],\n",
    "        right_on=['from_currency', 'year', 'month'],\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    # 4. Apply currency conversion for each amount column\n",
    "    for col in amount_cols:\n",
    "        merged_df[col] = merged_df[col] * merged_df['rate']\n",
    "\n",
    "    # 5. Drop unnecessary columns (from the lookup table like 'rate', 'from_currency')\n",
    "    merged_df = merged_df.drop(columns=['rate', 'from_currency', 'year', 'month'])\n",
    "\n",
    "    # 6. Concatenate the DKK and non-DKK dataframes\n",
    "    final_df = dd.concat([dkk_df, merged_df])\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path.home() / \"Library\" / \"CloudStorage\" / \"Dropbox\" / \"DTU\" / \"Virk2Vec\" / \"Tables\"\n",
    "path_financials = DATA_ROOT / \"Financials\"\n",
    "path_registrations = DATA_ROOT / \"Registrations\"\n",
    "path_currency = DATA_ROOT / \"Currency\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load files from the path_financials folder\n",
    "\n",
    "# Example: Get all .txt files in the folder\n",
    "financials_csv = [file for file in path_financials.iterdir() if file.is_file() and file.suffix == '.csv']\n",
    "registrations_csv = [file for file in path_registrations.iterdir() if file.is_file() and file.suffix == '.csv']\n",
    "currency_csv = [file for file in path_currency.iterdir() if file.is_file() and file.suffix == '.csv']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_registrations = [\n",
    "    \"CVR\",\n",
    "    \"FromDate\",\n",
    "    \"ChangeType\",\n",
    "    \"NewValue\"\n",
    "]\n",
    "\n",
    "columns_annualreport = [\n",
    "    \"CVR\",\n",
    "    \"PublicationDate\",\n",
    "    \"ProfitLoss\",\n",
    "    \"Equity\", \n",
    "    \"Assets\", \n",
    "    \"LiabilitiesAndEquity\"\n",
    "]\n",
    "\n",
    "columns_currency = [\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"from_currency\",\n",
    "    \"rate\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_registrations = dd.read_csv(\n",
    "    registrations_csv,\n",
    "    usecols=columns_registrations,\n",
    "    on_bad_lines=\"error\",\n",
    "    assume_missing=True,\n",
    "    dtype={\n",
    "        \"CVR\": int,\n",
    "        \"FromDate\": str,\n",
    "        \"ChangeType\": str,\n",
    "        \"NewValue\": str\n",
    "    },\n",
    "    blocksize=\"256MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_annualreport = dd.read_csv(\n",
    "    financials_csv,\n",
    "    usecols=columns_annualreport,\n",
    "    on_bad_lines=\"error\",\n",
    "    assume_missing=True,\n",
    "    dtype={\n",
    "        \"CVR\": int,\n",
    "        \"PublicationDate\": str,\n",
    "        \"Currency\": str,\n",
    "        \"ProfitLoss\": float,  # Deal with missing values\n",
    "        \"Equity\": float,\n",
    "        \"Assets\": float,\n",
    "        \"LiabilitiesAndEquity\": float,\n",
    "    },\n",
    "    blocksize=\"256MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ddf_currency = dd.read_csv(\n",
    "    currency_csv,\n",
    "    usecols=columns_currency,\n",
    "    on_bad_lines=\"error\",\n",
    "    assume_missing=True,\n",
    "    dtype={\n",
    "        \"year\": int,\n",
    "        \"month\": int,\n",
    "        \"from_currency\": str,\n",
    "        \"rate\": float\n",
    "    },\n",
    "    blocksize=\"256MB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>from_currency</th>\n",
       "      <th>rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2013</td>\n",
       "      <td>1</td>\n",
       "      <td>EUR</td>\n",
       "      <td>7.461371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2013</td>\n",
       "      <td>2</td>\n",
       "      <td>EUR</td>\n",
       "      <td>7.459788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2013</td>\n",
       "      <td>3</td>\n",
       "      <td>EUR</td>\n",
       "      <td>7.455241</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2013</td>\n",
       "      <td>4</td>\n",
       "      <td>EUR</td>\n",
       "      <td>7.452721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2013</td>\n",
       "      <td>5</td>\n",
       "      <td>EUR</td>\n",
       "      <td>7.453578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>787</th>\n",
       "      <td>2023</td>\n",
       "      <td>8</td>\n",
       "      <td>NOK</td>\n",
       "      <td>0.653141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>788</th>\n",
       "      <td>2023</td>\n",
       "      <td>9</td>\n",
       "      <td>NOK</td>\n",
       "      <td>0.650722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>789</th>\n",
       "      <td>2023</td>\n",
       "      <td>10</td>\n",
       "      <td>NOK</td>\n",
       "      <td>0.643006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>790</th>\n",
       "      <td>2023</td>\n",
       "      <td>11</td>\n",
       "      <td>NOK</td>\n",
       "      <td>0.632077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>791</th>\n",
       "      <td>2023</td>\n",
       "      <td>12</td>\n",
       "      <td>NOK</td>\n",
       "      <td>0.648455</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>792 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     year  month from_currency      rate\n",
       "0    2013      1           EUR  7.461371\n",
       "1    2013      2           EUR  7.459788\n",
       "2    2013      3           EUR  7.455241\n",
       "3    2013      4           EUR  7.452721\n",
       "4    2013      5           EUR  7.453578\n",
       "..    ...    ...           ...       ...\n",
       "787  2023      8           NOK  0.653141\n",
       "788  2023      9           NOK  0.650722\n",
       "789  2023     10           NOK  0.643006\n",
       "790  2023     11           NOK  0.632077\n",
       "791  2023     12           NOK  0.648455\n",
       "\n",
       "[792 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddf_currency.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['CVR', 'PublicationDate', 'ProfitLoss', 'Assets', 'Equity',\n",
      "       'LiabilitiesAndEquity'],\n",
      "      dtype='object')\n",
      "Index(['CVR', 'FromDate', 'ChangeType', 'NewValue'], dtype='object')\n",
      "Index(['year', 'month', 'from_currency', 'rate'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "#print columns\n",
    "print(ddf_annualreport.columns)\n",
    "print(ddf_registrations.columns)\n",
    "print(ddf_currency.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2531733\n",
      "4858471\n",
      "792\n"
     ]
    }
   ],
   "source": [
    "#how many rows in dd_test\n",
    "print(ddf_annualreport.shape[0].compute())\n",
    "print(ddf_registrations.shape[0].compute())\n",
    "print(ddf_currency.shape[0].compute())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert currency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enrich the annual report with asof values from the registrations\n",
    "ddf = dd_enrich_with_asof_values(\n",
    "    ddf_annualreport, \n",
    "    ddf_registrations, \n",
    "    values=['Industry', 'CompanyType', 'Address', 'Status'], \n",
    "    date_col_df='PublicationDate', \n",
    "    date_col_registrations='FromDate'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  PublicationDate       CVR  ProfitLoss     Assets     Equity  \\\n",
      "0      2013-01-01  31476836    426447.0  1137021.0   614372.0   \n",
      "1      2013-01-01  33160186   -138981.0   130682.0   -58981.0   \n",
      "2      2013-01-01  32146651     40309.0   297813.0   137137.0   \n",
      "3      2013-01-01  32827306    100208.0   847037.0    64665.0   \n",
      "4      2013-01-01  27193838   -248638.0  1809089.0 -1480356.0   \n",
      "\n",
      "   LiabilitiesAndEquity Industry CompanyType Address                 Status  \n",
      "0             1137021.0   711290         APS    7500                 NORMAL  \n",
      "1              130682.0   563000         APS    2100  UNDER TVANGSOPLØSNING  \n",
      "2              297813.0   464100         APS    8700                 NORMAL  \n",
      "3              847037.0   561010         APS    7400                 NORMAL  \n",
      "4             1809089.0   476430         APS    2150                 NORMAL  \n"
     ]
    }
   ],
   "source": [
    "#show the first 5 rows of test\n",
    "print(ddf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2531733\n"
     ]
    }
   ],
   "source": [
    "#length of test\n",
    "print(len(ddf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print list of column names\n",
    "columns = ddf.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_columns = [\n",
    "    \"START_DATE\",\n",
    "    \"CVR\",\n",
    "    \"PROFIT_LOSS\",\n",
    "    \"ASSETS\",\n",
    "    \"EQUTY\",\n",
    "    \"LIABILITIES_AND_EQUITY\",\n",
    "    \"INDUSTRY\",\n",
    "    \"COMPANY_TYPE\",\n",
    "    \"MUNICIPALITY\",\n",
    "    \"STATUS\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'PublicationDate': 'START_DATE',\n",
       " 'CVR': 'CVR',\n",
       " 'ProfitLoss': 'PROFIT_LOSS',\n",
       " 'Assets': 'ASSETS',\n",
       " 'Equity': 'EQUTY',\n",
       " 'LiabilitiesAndEquity': 'LIABILITIES_AND_EQUITY',\n",
       " 'Industry': 'INDUSTRY',\n",
       " 'CompanyType': 'COMPANY_TYPE',\n",
       " 'Address': 'MUNICIPALITY',\n",
       " 'Status': 'STATUS'}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(zip(columns, output_columns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parsed(self) -> dd.DataFrame:\n",
    "    \"\"\"Parses the CSV file, applies some basic filtering, then saves the result\n",
    "    as compressed parquet file, as this is easier to parse than the CSV for the\n",
    "    next steps\"\"\"\n",
    "\n",
    "    columns_registrations = [\n",
    "        \"CVR\",\n",
    "        \"FromDate\",\n",
    "        \"ChangeType\",\n",
    "        \"NewValue\"\n",
    "    ]\n",
    "\n",
    "    columns_annualreport = [\n",
    "        \"CVR\",\n",
    "        \"PublicationDate\",\n",
    "        \"ProfitLoss\",\n",
    "        \"Equity\", \n",
    "        \"Assets\", \n",
    "        \"LiabilitiesAndEquity\"\n",
    "    ]\n",
    "\n",
    "    columns_currency = [\n",
    "    \"year\",\n",
    "    \"month\",\n",
    "    \"from_currency\",\n",
    "    \"rate\"\n",
    "    ]\n",
    "\n",
    "    output_columns = [\n",
    "    \"START_DATE\",\n",
    "    \"CVR\",\n",
    "    \"PROFIT_LOSS\",\n",
    "    \"ASSETS\",\n",
    "    \"EQUTY\",\n",
    "    \"LIABILITIES_AND_EQUITY\",\n",
    "    \"INDUSTRY\",\n",
    "    \"COMPANY_TYPE\",\n",
    "    \"MUNICIPALITY\",\n",
    "    \"STATUS\"\n",
    "    ]\n",
    "    \n",
    "    # Update the path to the data\n",
    "    path_financials = self.input_csv / \"Financials\"\n",
    "    path_registrations = self.input_csv  / \"Registrations\"\n",
    "    path_currency = self.input_csv / \"Currency\"\n",
    "    \n",
    "    # Load files\n",
    "    financials_csv = [file for file in path_financials.iterdir() if file.is_file() and file.suffix == '.csv']\n",
    "    registrations_csv = [file for file in path_registrations.iterdir() if file.is_file() and file.suffix == '.csv']\n",
    "    currency_csv = [file for file in path_currency.iterdir() if file.is_file() and file.suffix == '.csv']\n",
    "    \n",
    "    # Load data\n",
    "    ddf_registrations = dd.read_csv(\n",
    "        registrations_csv,\n",
    "        usecols=columns_registrations,\n",
    "        on_bad_lines=\"error\",\n",
    "        assume_missing=True,\n",
    "        dtype={\n",
    "            \"CVR\": int,\n",
    "            \"FromDate\": str,\n",
    "            \"ChangeType\": str,\n",
    "            \"NewValue\": str\n",
    "        },\n",
    "        blocksize=\"256MB\"\n",
    "    )\n",
    "    \n",
    "    ddf_annualreport = dd.read_csv(\n",
    "        financials_csv,\n",
    "        usecols=columns_annualreport,\n",
    "        on_bad_lines=\"error\",\n",
    "        assume_missing=True,\n",
    "        dtype={\n",
    "            \"CVR\": int,\n",
    "            \"PublicationDate\": str,\n",
    "            \"ProfitLoss\": float,\n",
    "            \"Equity\": float,\n",
    "            \"Assets\": float,\n",
    "            \"LiabilitiesAndEquity\": float,\n",
    "        },\n",
    "        blocksize=\"256MB\"\n",
    "        )\n",
    "    \n",
    "    ddf_currency = dd.read_csv(\n",
    "        currency_csv,\n",
    "        usecols=columns_currency,\n",
    "        on_bad_lines=\"error\",\n",
    "        assume_missing=True,\n",
    "        dtype={\n",
    "            \"year\": int,\n",
    "            \"month\": int,\n",
    "            \"from_currency\": str,\n",
    "            \"rate\": float\n",
    "        },\n",
    "        blocksize=\"256MB\"\n",
    "        )\n",
    "    \n",
    "    # enrich the annual report with asof values from the registrations\n",
    "    ddf = dd_enrich_with_asof_values(\n",
    "        ddf_annualreport, \n",
    "        ddf_registrations, \n",
    "        values=['Industry', 'CompanyType', 'Address', 'Status'], \n",
    "        date_col_df='PublicationDate', \n",
    "        date_col_registrations='FromDate'\n",
    "        )\n",
    "    \n",
    "    # convert currency\n",
    "\n",
    "    \n",
    "    columns = ddf.columns\n",
    "\n",
    "    #nået hertil ----------------------------------------------------------\n",
    "    \n",
    "    # Drop missing values and deal with datatypes\n",
    "    ddf = (\n",
    "        ddf.dropna(subset=[\"PERSON_ID\", \"C_ADIAG\"])\n",
    "        .assign(\n",
    "            PERSON_ID=lambda x: x.PERSON_ID.astype(int),\n",
    "            D_INDDTO=lambda x: dd.to_datetime(\n",
    "                x.D_INDDTO,\n",
    "                format=\"%d%b%Y:%X\",\n",
    "                errors=\"coerce\",\n",
    "            ),\n",
    "        )\n",
    "        .rename(columns=dict(zip(columns, output_columns)))\n",
    "        .loc[lambda x: x.START_DATE >= self.earliest_start]\n",
    "    )\n",
    "\n",
    "    if self.downsample:\n",
    "        ddf = self.downsample_persons(ddf)\n",
    "\n",
    "    assert isinstance(ddf, dd.DataFrame)\n",
    "\n",
    "    return ddf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ABA",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
